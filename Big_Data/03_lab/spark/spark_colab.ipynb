{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rodeffs/Year4_Programming/blob/master/Big_Data/03_lab/spark/spark_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wHb2w1x26Pl"
      },
      "source": [
        "Checking java version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrL84LNuFeb3",
        "outputId": "21177868-8fdc-4926-93f5-7fff4f85bad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "openjdk 17.0.16 2025-07-15\n",
            "OpenJDK Runtime Environment (build 17.0.16+8-Ubuntu-0ubuntu122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.16+8-Ubuntu-0ubuntu122.04.1, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "!java --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpZmg3fX3AsG"
      },
      "source": [
        "Installing Apache Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWYhIEJU3NkV",
        "outputId": "dc47cad1-71a7-49bf-ddf2-ecbb4e4ea38a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-12-05 18:53:48--  https://dlcdn.apache.org/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 548955321 (524M) [application/x-gzip]\n",
            "Saving to: ‘spark-4.0.1-bin-hadoop3.tgz’\n",
            "\n",
            "spark-4.0.1-bin-had 100%[===================>] 523.52M  24.2MB/s    in 7.7s    \n",
            "\n",
            "2025-12-05 18:54:19 (68.1 MB/s) - ‘spark-4.0.1-bin-hadoop3.tgz’ saved [548955321/548955321]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dlcdn.apache.org/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDo1WTKY3YH3"
      },
      "outputs": [],
      "source": [
        "!tar -xf spark-4.0.1-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1-URVTR39Al"
      },
      "source": [
        "Python libraries to work with Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0J6afWG38fQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT-yxbB45Djy"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-F7Hx8g4I7G"
      },
      "source": [
        "Installing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYetYRl74JSz",
        "outputId": "ea1380f5-6c59-4b0c-9872-15e702829acc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1409M  100 1409M    0     0  67.3M      0  0:00:20  0:00:20 --:--:-- 74.9M\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://www.kaggle.com/api/v1/datasets/download/beta3logic/3m-academic-papers-titles-and-abstracts -o dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNf-7mKX4f_L",
        "outputId": "b840e665-d937-46c9-d1ea-e1cceb6f4fcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  dataset.zip\n",
            "  inflating: cleaned_papers.csv      \n"
          ]
        }
      ],
      "source": [
        "!unzip dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDaqKaas9LhW"
      },
      "source": [
        "Setting the variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK1McbTB9F1z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
        "os.environ[\"JRE_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64/jre\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-4.0.1-bin-hadoop3\"\n",
        "os.environ[\"PATH\"] += \":$JAVA_HOME/bin:$JRE_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnX_0_OT9buF"
      },
      "source": [
        "Now we can begin to work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKEQ5q229beN"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark = SparkSession.builder.appName(\"popular_topics\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HymfRv5i-QPn",
        "outputId": "f3d2518d-9f6f-4df5-a282-42c21a1c9b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|               title|            abstract|\n",
            "+--------------------+--------------------+\n",
            "|Dynamic Backtracking|Because of their ...|\n",
            "|A Market-Oriented...|Market price syst...|\n",
            "|An Empirical Anal...|We describe an ex...|\n",
            "|The Difficulties ...|As real logic pro...|\n",
            "|Software Agents: ...|To support the go...|\n",
            "|Decidable Reasoni...|Terminological kn...|\n",
            "|Teleo-Reactive Pr...|A formalism is pr...|\n",
            "|Learning the Past...|Learning the past...|\n",
            "|Substructure Disc...|The ability to id...|\n",
            "|Bias-Driven Revis...|The theory revisi...|\n",
            "|Exploring the Dec...|We report on a se...|\n",
            "|A Semantics and C...|This paper analyz...|\n",
            "|Applying GSAT to ...|In this paper we ...|\n",
            "|Random Worlds and...|Given a knowledge...|\n",
            "|Pattern Matching ...|Information extra...|\n",
            "|A System for Indu...|This article desc...|\n",
            "|On Planning while...|This paper introd...|\n",
            "|Wrap-Up: a Traina...|The vast amounts ...|\n",
            "|Operations for Le...|This paper is a m...|\n",
            "|Total-Order and P...|For many years, t...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Reading the CSV\n",
        "\n",
        "df = spark.read.csv(\"/content/cleaned_papers.csv\", header=True, sep=',', quote='\"', escape='\"', multiLine=True)\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPqBWAKMAsSy",
        "outputId": "8f8d4103-7f67-4044-b831-bdf4ed8e68bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|               entry|\n",
            "+--------------------+\n",
            "|dynamic backtrack...|\n",
            "|a market-oriented...|\n",
            "|an empirical anal...|\n",
            "|the difficulties ...|\n",
            "|software agents: ...|\n",
            "|decidable reasoni...|\n",
            "|teleo-reactive pr...|\n",
            "|learning the past...|\n",
            "|substructure disc...|\n",
            "|bias-driven revis...|\n",
            "|exploring the dec...|\n",
            "|a semantics and c...|\n",
            "|applying gsat to ...|\n",
            "|random worlds and...|\n",
            "|pattern matching ...|\n",
            "|a system for indu...|\n",
            "|on planning while...|\n",
            "|wrap-up: a traina...|\n",
            "|operations for le...|\n",
            "|total-order and p...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Adding a column that unifies title and abstract into one\n",
        "\n",
        "df = df.withColumn(\"entry\", F.concat_ws(\". \", \"title\", \"abstract\"))\n",
        "df = df.withColumn(\"entry\", F.lower(\"entry\"))  # проще работать в нижнем регистре\n",
        "df = df.withColumn(\"entry\", F.regexp_replace(F.col(\"entry\"), r\"\\s*\\n\\s*\", ' '))  # убрать лишние переносы строки\n",
        "df = df.drop(\"title\", \"abstract\")  # они больше не нужны\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4l_j8GiF8KA",
        "outputId": "7bfbeac4-3347-48e2-ebbd-2b1bcb9de42d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|               entry|\n",
            "+--------------------+\n",
            "|dynamic backtracking|\n",
            "|     occasional need|\n",
            "|      shallow points|\n",
            "|         search tree|\n",
            "|existing backtrac...|\n",
            "|sometimes erase m...|\n",
            "|      search problem|\n",
            "|    backtrack points|\n",
            "|        moved deeper|\n",
            "|        search space|\n",
            "|    thereby avoiding|\n",
            "| technique developed|\n",
            "|dependency-direct...|\n",
            "|only polynomial s...|\n",
            "|still providing u...|\n",
            "|completeness guar...|\n",
            "|  earlier approaches|\n",
            "|market-oriented p...|\n",
            "|distributed multi...|\n",
            "|market price syst...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Now we use regexp to split each row into word combinations\n",
        "\n",
        "regexp = r\"([^a-z^\\s^'^-])|(?:^|[^a-z])['-]|['-](?:^|[^a-z])|'*(?<![a-z-])(?:a|an|the|and|or|as|of|in|on|yet|our|than|then|however|at|but|was|were|which|there|this|that|thus|we|to|for|is|are|where|have|has|been|since|with|such|another|also|by|often|can|could|so|from|its|via|will|hence|should|would|shall|what|although|these|those|do|does|did|under|above|else|if|while|when|who|based|way|very|many|much|due|because|onto|into|out|finally|their|they|may|might|up|down|either|neither|nor|within|according|others|about|therefore|no|not|towards|beyond|behind|over|how|both|without|other|another|more|most|moreover|be|furthermore|why|paper|focuses|well|must|consider|using|used|commonly|some|given|among|able|present|his|her|he|she|obtained|makes|give|make|further|use|introduce|employ|uses|show|allows|gives|introduces|considers|through|take|takes|enable|enables|allow|every|each|called|provide|provides|cannot|allowing|even|though|after|around|upon|you|new)(?![a-z-])'*\"\n",
        "\n",
        "df_entry = df.select(F.explode(F.split(F.col(\"entry\"), regexp)).alias(\"entry\"))\n",
        "df_entry = df_entry.withColumn(\"entry\", F.trim(F.col(\"entry\")))  # обрезаем лишние пробелы\n",
        "df_entry = df_entry.filter(F.size(F.split(F.col(\"entry\"), r\"\\s+\")) >= 2)  # за темы считаем комбинации слов >= 2\n",
        "\n",
        "df_entry.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6mBEr3xJ9gq",
        "outputId": "dc23d471-f1fd-400a-965a-777e5aaebf61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|               entry|value|\n",
            "+--------------------+-----+\n",
            "|dynamic backtracking|    1|\n",
            "|     occasional need|    1|\n",
            "|      shallow points|    1|\n",
            "|         search tree|    1|\n",
            "|existing backtrac...|    1|\n",
            "|sometimes erase m...|    1|\n",
            "|      search problem|    1|\n",
            "|    backtrack points|    1|\n",
            "|        moved deeper|    1|\n",
            "|        search space|    1|\n",
            "|    thereby avoiding|    1|\n",
            "| technique developed|    1|\n",
            "|dependency-direct...|    1|\n",
            "|only polynomial s...|    1|\n",
            "|still providing u...|    1|\n",
            "|completeness guar...|    1|\n",
            "|  earlier approaches|    1|\n",
            "|market-oriented p...|    1|\n",
            "|distributed multi...|    1|\n",
            "|market price syst...|    1|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Mapping\n",
        "\n",
        "df_mapped = df_entry.withColumn(\"value\", F.lit(1))\n",
        "\n",
        "df_mapped.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPaJICd4NGKU",
        "outputId": "3f82fdb5-e820-44dd-e25b-00262b7fe88f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|               entry|total|\n",
            "+--------------------+-----+\n",
            "|experimental results|49397|\n",
            "|          wide range|49310|\n",
            "|     proposed method|43782|\n",
            "|    machine learning|41577|\n",
            "|large language mo...|40533|\n",
            "|          first time|40390|\n",
            "|      magnetic field|34954|\n",
            "|       deep learning|33439|\n",
            "|        recent years|33121|\n",
            "|extensive experim...|29208|\n",
            "|     results suggest|29061|\n",
            "|        large number|28488|\n",
            "|      standard model|27719|\n",
            "|      important role|26117|\n",
            "| confidence interval|25524|\n",
            "|         dark matter|24879|\n",
            "|     neural networks|24831|\n",
            "|numerical simulat...|24760|\n",
            "|    results indicate|22983|\n",
            "|reinforcement lea...|22299|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Reduce\n",
        "\n",
        "df_result = df_mapped.groupBy(\"entry\").agg(F.sum(\"value\").alias(\"total\")).orderBy(\"total\", ascending=False)\n",
        "\n",
        "df_result.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNJqhdyVoOrckyAHOB+JYA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}