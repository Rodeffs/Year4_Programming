{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxuYkPw4w3HY0nsVF5ksIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rodeffs/Year4_Programming/blob/master/Big_Data/03_lab/hadoop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking java version"
      ],
      "metadata": {
        "id": "GYOAvZYlI09k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!java --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyMiKdsTI4G4",
        "outputId": "cb698cdd-a561-449f-d425-4d0d6fa602ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk 17.0.16 2025-07-15\n",
            "OpenJDK Runtime Environment (build 17.0.16+8-Ubuntu-0ubuntu122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.16+8-Ubuntu-0ubuntu122.04.1, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Hadoop"
      ],
      "metadata": {
        "id": "1jKdzEczI-13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpymaiaLI9x5",
        "outputId": "17399fd9-c309-4a93-ce8b-8d8c793068ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-02 08:38:59--  https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1065831750 (1016M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.4.2.tar.gz’\n",
            "\n",
            "hadoop-3.4.2.tar.gz 100%[===================>]   1016M  59.9MB/s    in 11s     \n",
            "\n",
            "2025-12-02 08:39:11 (89.0 MB/s) - ‘hadoop-3.4.2.tar.gz’ saved [1065831750/1065831750]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf hadoop-3.4.2.tar.gz"
      ],
      "metadata": {
        "id": "0CLlXK_cKR0I",
        "outputId": "0b013179-c61d-46bf-8127-71a7fda08850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: hadoop: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the dataset"
      ],
      "metadata": {
        "id": "RB1ZEtWfP2Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L https://www.kaggle.com/api/v1/datasets/download/beta3logic/3m-academic-papers-titles-and-abstracts -o dataset.zip"
      ],
      "metadata": {
        "id": "kFG1uYIrP-SH",
        "outputId": "cb209c47-5b06-42e1-9e23-834947a4b5f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1409M  100 1409M    0     0  93.1M      0  0:00:15  0:00:15 --:--:--  111M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip"
      ],
      "metadata": {
        "id": "cqkE4wlUQsaR",
        "outputId": "d96f226d-70c7-4ab4-d914-958a8fe5faf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset.zip\n",
            "  inflating: cleaned_papers.csv      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the variables"
      ],
      "metadata": {
        "id": "dIuOPxUsIqVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFiman4LExZQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
        "os.environ[\"JRE_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64/jre\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/content/hadoop-3.4.2\"\n",
        "os.environ[\"PATH\"] += \":$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting dataset into multiple files"
      ],
      "metadata": {
        "id": "zJZhuhOi1y5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile splitter.py\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df_input = \"/content/cleaned_papers.csv\"\n",
        "\n",
        "df = pd.read_csv(df_input)\n",
        "i, j = 0, 0\n",
        "max_lines = 100000\n",
        "file = open(f\"/content/datasets/dataset{j}.txt\", mode=\"w\", encoding=\"utf-8\")\n",
        "\n",
        "for row in df.itertuples(index=False):\n",
        "    line = str(row.title + \". \" + row.abstract).lower()  # объединить оба столбца и перевести в нижний регистр\n",
        "    line = re.sub(r\"\\s*\\n\\s*\", ' ', line)  # убрать переносы на след. строку\n",
        "    file.write(line + \"\\n\")\n",
        "    i += 1\n",
        "\n",
        "    if i == max_lines:\n",
        "        file.close()\n",
        "        i = 0\n",
        "        j += 1\n",
        "        file = open(f\"/content/datasets/dataset{j}.txt\", mode=\"w\", encoding=\"utf-8\")\n",
        "\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "mVC6caFb1yic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir datasets"
      ],
      "metadata": {
        "id": "7qoZr0e22bKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python splitter.py"
      ],
      "metadata": {
        "id": "T2DLBCHH2dK4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}