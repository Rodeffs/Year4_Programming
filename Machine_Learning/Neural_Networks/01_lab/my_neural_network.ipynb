{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32dc1b13-52b9-4f13-8ceb-c8da5b58d5c1",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8d5c16-1faf-40b2-b214-abbb84dff942",
   "metadata": {},
   "source": [
    "## Задания\n",
    "\n",
    "Самостоятельно написать код, реализующий искусственный нейрон с сигма-функцией активации, и возможность строить на его основе многослойные сети. Код должен также реализовывать градиентный спуск и обратное распространение ошибки.\n",
    "\n",
    "На основе вашего кода:\n",
    "\n",
    "1. Решить задачу  классификации датаcета Iris одним нейроном.\n",
    "2. Решить задачу  классификации датаcета Iris одним  нейросетью из 2 слоев по 10 нейронов в слое.\n",
    "3. Отрисовать разделяющую линию для обеих моделей. Сравнить метрики классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e874744-dd80-49c2-8fb3-937ee39e9b75",
   "metadata": {},
   "source": [
    "## Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced18f6c-63a0-4d64-98d5-d34949c427ff",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc1fe0b-3c79-40b0-9929-51da56945f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81ddf1-6093-4df9-b5ab-3c367e1549f4",
   "metadata": {},
   "source": [
    "### Функция активации\n",
    "\n",
    "В качестве неё берём сигма-функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba2eb9a-5d71-42a1-9139-e3375a273932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a3d558-61c1-4f7a-bce3-1c10edaaec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_activation(x):  # производная функции активации (уже посчитан вывод)\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5fd2c8-0636-4309-b841-db0a29e32f14",
   "metadata": {},
   "source": [
    "### Функция ошибок\n",
    "\n",
    "Т.к. это задача классификации, то будет использоваться функция ошибок Categorical Cross-Entropy Loss\n",
    "\n",
    "Её формула:\n",
    "\n",
    "```\n",
    "-sum_i(sum_j(y_ij * log(z_ij) + (1 - y_ij) * log(1 - z_ij)))\n",
    "```\n",
    "\n",
    "где\n",
    "\n",
    "* 1 <= i <= N, N - кол-во входных данных\n",
    "* 1 <= j <= C, C - кол-во классов\n",
    "* y_ij - индикатор 0 или 1, что класс j является правильным для элемента i\n",
    "* z_ij - предсказанная вероятность того, что у элемента i класс j\n",
    "* log - логарифм\n",
    "* sum_i - сумма по i\n",
    "* sum_j - сумма по j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50161bd-f875-47be-bf5a-a4e990686329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    N = len(y_true)\n",
    "    C = len(y_true[0])\n",
    "\n",
    "    total_sum = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        value_sum = 0\n",
    "        \n",
    "        for j in range(C):\n",
    "            p = y_pred[i][j]\n",
    "            t = y_true[i][j]\n",
    "\n",
    "            if p == 0:\n",
    "                value_sum += t\n",
    "\n",
    "            elif p == 1:\n",
    "                value_sum += (1-t)\n",
    "\n",
    "            else:\n",
    "                value_sum += t * np.log(p) + (1 - t) * np.log(1 - p)\n",
    "            \n",
    "        total_sum += value_sum\n",
    "            \n",
    "    return -total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29484cd8-0be7-4064-85bf-4f9be0e1bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_mult(y_true, y_pred):  # произведение производных функции ошибок и функции активации\n",
    "    return y_pred - y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9dd3c6-6466-4bd4-a646-e87b41e7c55d",
   "metadata": {},
   "source": [
    "### Слой нейронной сети\n",
    "\n",
    "Хранит матрицу весов нейронов, матрицу сдвигов нейронов, матрицу ошибок и вывод нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef66cdba-e574-4124-be84-7c04deb8791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, neuron_count):\n",
    "        self.neuron_count = neuron_count\n",
    "        self.weights = None  # матрица весов нейронов N x W, где N - кол-во нейронов в слое, а W - кол-во входных данных в слой\n",
    "        self.biases = None  # вектор сдвигов нейронов N x 1, где N - кол-во нейронов в слое\n",
    "        self.output = None  # вектор вывода N x 1\n",
    "        self.error = None  # вектор ошибок N x 1, нужен для обратного распространения ошибки в градиентном спуске\n",
    "\n",
    "    \n",
    "    def setup_layer(self, input_count):\n",
    "        self.weights = np.zeros((self.neuron_count, input_count))\n",
    "\n",
    "        for i in range(self.neuron_count):  # изначальные веса равны N(0, 2 / (n + w)), где n - кол-во нейронов, w - кол-во входов, N - нормальное распределение\n",
    "            for j in range(input_count):\n",
    "                self.weights[i][j] = np.random.normal(0, 2 / (self.neuron_count + input_count))  \n",
    "                \n",
    "        self.biases = np.zeros((self.neuron_count, 1))  # изначальный сдвиг равен 0\n",
    "\n",
    "    \n",
    "    def input_output(self, input_values):\n",
    "        self.output = activation((self.weights @ input_values) + self.biases)  # вектор вывода, здесь F(WX + B), где X - вектор входных данных, W - матрица весов, B - вектор сдвигов\n",
    "        \n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ed3db-c3bb-48f9-b13f-b3caef263014",
   "metadata": {},
   "source": [
    "### Нейронная сеть\n",
    "\n",
    "Сеть состоит из слоёв, здесь определяется её поведение\n",
    "\n",
    "X и y нужно преобразовать перед тем, как работать с ними\n",
    "\n",
    "Предположим, для задачи классификации есть 4 возможных вывода (0, 1, 2, 3) и y выглядит так:\n",
    "\n",
    "```\n",
    "| y |\n",
    "|---|\n",
    "| 0 |\n",
    "| 2 |\n",
    "| 1 |\n",
    "| 2 | \n",
    "| 3 |\n",
    "| 1 |\n",
    "```\n",
    "\n",
    "Нейроны выдают значения от 0 до 1, и чтобы классификация прошла правильно, преобразуем данные в матрицу вхождений\n",
    "\n",
    "```\n",
    "| y |     |    y    |\n",
    "|---|     |---------|\n",
    "| 0 | --> | 1 0 0 0 |\n",
    "| 2 | --> | 0 0 1 0 |\n",
    "| 1 | --> | 0 1 0 0 |\n",
    "| 2 | --> | 0 0 1 0 |\n",
    "| 3 | --> | 0 0 0 1 |\n",
    "| 1 | --> | 0 1 0 0 | \n",
    "```\n",
    "\n",
    "Также нужно нормализировать входные данные в пределах (-1, 1), тогда mean = 0, а var = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d8896ba-a343-4b00-9d13-cc66327e0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNetwork:\n",
    "    def __init__(self, layers=[]):\n",
    "        self.layers = layers\n",
    "\n",
    "    \n",
    "    def back_propogation(self, true_values):  # обратное распространение ошибки\n",
    "        for layer in range(len(self.layers) - 1, -1, -1):  # идём в обратном порядке, в этом суть метода\n",
    "            cur_layer = self.layers[layer]\n",
    "            \n",
    "            if layer == len(self.layers) - 1:\n",
    "                # Для выходного слоя вектор ошибок будет выглядеть так: L'(t, o) * f'(i), где:\n",
    "                # L' - производная функции ошибок, f' - производная функции активации\n",
    "                # o - вывод значений нынешнего слоя, t - истинный вывод, i - вывод значений предыдущего слоя\n",
    "                # Важное замечание: у функции активации сигма, производная равна f(i)(1 - f(i))\n",
    "                # Т.к. мы уже знаем, что o = f(i), то тогда f'(i) = o(1 - o)\n",
    "                \n",
    "                cur_layer.error = der_mult(true_values, cur_layer.output)\n",
    "\n",
    "            else:\n",
    "                # Для остальных слоёв вектор ошибок будет такой: TD * f'(i), где:\n",
    "                # D - вектор ошибок следующего слоя, T - транспонированная матрица весов следующего слоя\n",
    "                # f' - производная функции активации, o - вывод значений нынешнего слоя, i - вывод значений предыдущего слоя\n",
    "                # Важное замечание: у функции активации сигма, производная равна f(i)(1 - f(i))\n",
    "                # Т.к. мы уже знаем, что o = f(i), то тогда f'(i) = o(1 - o)\n",
    "                \n",
    "                next_layer = self.layers[layer + 1]\n",
    "                cur_layer.error = (next_layer.weights.transpose() @ next_layer.error) * der_activation(cur_layer.output)\n",
    "                \n",
    "    \n",
    "    def gradient_descent(self, input_values, learning_rate):  # градиентный спуск\n",
    "        for layer in range(len(self.layers)):  # теперь идём по порядку, так называемый forward progogation     \n",
    "            cur_layer = self.layers[layer]\n",
    "\n",
    "            # Изменение сдвигов равно E*l, где l - скорость обучения, E - вектор ошибок\n",
    "\n",
    "            delta_biases = cur_layer.error * learning_rate \n",
    "\n",
    "            # Изменение весов равно ET*l, где l - скорость обучения, E - вектор ошибок, T - транспонированная матрица вводных данных слоя\n",
    "\n",
    "            delta_weights = None\n",
    "\n",
    "            if layer == 0:\n",
    "                delta_weights = (cur_layer.error @ input_values.transpose()) * learning_rate\n",
    "\n",
    "            else:\n",
    "                prev_layer = self.layers[layer - 1]\n",
    "                delta_weights = (cur_layer.error @ prev_layer.output.transpose()) * learning_rate\n",
    "\n",
    "            cur_layer.weights -= delta_weights\n",
    "            cur_layer.biases -= delta_biases\n",
    "\n",
    "\n",
    "    def normalise(self, X):  # нормализация входных данных\n",
    "        normalised = X.copy()\n",
    "    \n",
    "        for i in range(normalised.shape[1]):        \n",
    "            normalised[:, i] = (normalised[:, i] - normalised[:, i].mean()) / (normalised[:, i].max() - normalised[:, i].min())\n",
    "    \n",
    "        return normalised\n",
    "\n",
    "\n",
    "    def one_hot_transform(self, y, target_classes):  # преобразование в матрицу вхождений\n",
    "        transformed = []\n",
    "    \n",
    "        for i in range(len(y)):\n",
    "            instances = []\n",
    "            \n",
    "            for j in range(len(target_classes)):\n",
    "                if y[i] == target_classes[j]:\n",
    "                    instances.append(1)\n",
    "\n",
    "                else:\n",
    "                    instances.append(0)\n",
    "\n",
    "            transformed.append(instances)\n",
    "    \n",
    "        return np.array(transformed)\n",
    "\n",
    "\n",
    "    def back_transform(self, y, target_classes):  # обратное преобразование в класс\n",
    "        initial = []\n",
    "    \n",
    "        for i in range(len(y)):\n",
    "            for j in range(len(target_classes)):\n",
    "                transformed[i][y[i]] = 1\n",
    "\n",
    "            initial.append(instances)\n",
    "    \n",
    "        return np.array(initial)\n",
    "\n",
    "        \n",
    "    def fit(self, X, y, target_classes, learning_rate=0.1, epochs=1000, verbose=False, early_stopping=None):\n",
    "        X_train = self.normalise(X)\n",
    "        y_test = self.one_hot_transform(y, target_classes)\n",
    "        \n",
    "        \n",
    "        for layer in range(len(self.layers)):  # инициализация слоёв\n",
    "            if layer == 0:\n",
    "                self.layers[layer].setup_layer(len(X_train[0]))  # первый слой - входной, у него кол-во входных данных равно кол-ву вводимых атрибутов\n",
    "\n",
    "            else:\n",
    "                self.layers[layer].setup_layer(self.layers[layer-1].neuron_count)  # у каждого последующего слоя кол-во входных данных равно кол-ву нейронов на предыдущем слое\n",
    "\n",
    "        last_error = None\n",
    "\n",
    "        for epoch in range(epochs):  # начало обучения\n",
    "            y_pred = []\n",
    "            \n",
    "            for value in range(len(X_train)):\n",
    "                input_values = np.array([X_train[value]]).transpose()  # входные данные в виде вектор-столбца\n",
    "                true_values = np.array([y_train[value]]).transpose()  # истинные данные в виде вектор-столбца\n",
    "                \n",
    "                neuron_output = input_values  # в первый слой идут входные данные\n",
    "\n",
    "                for layer in range(len(self.layers)):       \n",
    "                    neuron_output = self.layers[layer].input_output(neuron_output)\n",
    "\n",
    "                y_pred.append(neuron_output.transpose()[0])  # значение последнего слоя и будет предсказанным значением\n",
    "                \n",
    "                self.back_propogation(true_values)  # считаем обратное распространение ошибки\n",
    "                self.gradient_descent(input_values, learning_rate)  # выполняем градиентный спуск\n",
    "\n",
    "            y_pred = np.array(y_pred)\n",
    "            error = loss(y_train, y_pred)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1} out of {epochs}, current error is {error}\")\n",
    "\n",
    "            if early_stopping is not None:  # early stopping - минимальное значение разницы ошибок последних двух итераций, меньше которого обучение останавливается\n",
    "                if last_error is not None:\n",
    "                    if abs(error - last_error) < early_stopping:\n",
    "                        if verbose:\n",
    "                            print(\"Stopping early\")\n",
    "                        return\n",
    "\n",
    "                last_error = error\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_test = self.normalise(X)\n",
    "        \n",
    "        y_pred = []  # предсказанные значения\n",
    "\n",
    "        for value in range(len(X_test)):            \n",
    "            neuron_output = np.array([X_test[value]]).transpose()  # входные данные в виде вектор-столбца\n",
    "\n",
    "            for layer in range(len(self.layers)):    \n",
    "                neuron_output = self.layers[layer].input_output(neuron_output)\n",
    "\n",
    "            y_pred.append(neuron_output.transpose()[0])  # значение последнего слоя и будет предсказанным значением\n",
    "\n",
    "        return self.back_transform(np.array(y_pred))  # получили предсказание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63b78b-0254-4f21-a51c-849b7f09e859",
   "metadata": {},
   "source": [
    "### Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d494681-d500-4fac-845a-61b4417d5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_iris()\n",
    "X, y = df[\"data\"], df[\"target\"]\n",
    "target_classes = [0, 1, 2] # какие классы рассматриваем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e969371d-90ce-4e61-8d59-d249ef9a6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8bd4a-7478-4bfc-9aaf-a9560f0c77ec",
   "metadata": {},
   "source": [
    "### Сеть из 1 слоя с 1 нейроном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "012537a3-f030-4598-bc35-5e8900a294c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = ClassificationNetwork([\n",
    "    Layer(1),\n",
    "    Layer(types)  # кол-во нейронов на выходном слою равно кол-ву типов классификации\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "009d8419-3594-49e6-87eb-20d8ea6a50e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X_train, y_train, verbose=False, learning_rate=0.1, epochs=5000, early_stopping=10**-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5e7e0c-1382-4d83-9216-04eed6aa745e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99921710e-01, 6.90315078e-02, 7.79277611e-34],\n",
       "       [1.69792175e-03, 2.65580902e-01, 2.33008035e-10],\n",
       "       [1.07652333e-05, 3.75080868e-01, 7.43021936e-03],\n",
       "       [8.21475265e-07, 4.37093833e-01, 9.79970441e-01],\n",
       "       [1.26964310e-06, 4.26403342e-01, 9.17112293e-01],\n",
       "       [9.99860572e-01, 7.28377289e-02, 5.59203568e-33],\n",
       "       [9.99899011e-01, 7.06873457e-02, 1.85889290e-33],\n",
       "       [1.71119550e-06, 4.19113988e-01, 7.99746213e-01],\n",
       "       [1.00390441e-06, 4.32161665e-01, 9.61043167e-01],\n",
       "       [5.53625963e-05, 3.37516459e-01, 2.79193402e-05],\n",
       "       [9.99674425e-01, 7.87828892e-02, 1.01240026e-31],\n",
       "       [7.82520094e-05, 3.29816317e-01, 8.56594575e-06],\n",
       "       [1.25280787e-06, 4.26730132e-01, 9.20511680e-01],\n",
       "       [5.47515337e-05, 3.37764896e-01, 2.89976810e-05],\n",
       "       [2.15531879e-05, 3.58941698e-01, 6.99096377e-04],\n",
       "       [8.22099803e-07, 4.37075119e-01, 9.79919445e-01],\n",
       "       [1.57283393e-06, 4.21169782e-01, 8.41919985e-01],\n",
       "       [1.93285197e-04, 3.10126716e-01, 3.90647479e-07],\n",
       "       [1.12932208e-05, 3.73958279e-01, 6.31667706e-03],\n",
       "       [3.15159100e-04, 2.99753598e-01, 7.35584479e-08],\n",
       "       [9.28305448e-07, 4.34085552e-01, 9.69906156e-01],\n",
       "       [1.49818300e-05, 3.67359700e-01, 2.41592884e-03],\n",
       "       [5.07764104e-06, 3.92868812e-01, 8.87552671e-02],\n",
       "       [1.81250511e-06, 4.17713150e-01, 7.66441087e-01],\n",
       "       [1.04172507e-06, 4.31253615e-01, 9.56030699e-01],\n",
       "       [9.99788613e-01, 7.57014298e-02, 2.31602659e-32],\n",
       "       [1.19979315e-06, 4.27789102e-01, 9.30665011e-01],\n",
       "       [5.21516647e-05, 3.38854917e-01, 3.42376134e-05],\n",
       "       [2.65151327e-04, 3.03396847e-01, 1.32710578e-07],\n",
       "       [8.62068348e-07, 4.35906462e-01, 9.76469131e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = model1.predict(X_test)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec61da-805a-4f7c-9d63-4f767300ccc4",
   "metadata": {},
   "source": [
    "### Сеть из 2 слоёв по 10 нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54272f86-c1bc-4635-bfce-7c51a82228b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ClassificationNetwork([\n",
    "    Layer(10),\n",
    "    Layer(10),\n",
    "    Layer(types)  # кол-во нейронов на выходном слою равно кол-ву типов классификации\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df4c92c9-cff7-4f22-9bda-1aeb93572fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_train, y_train, verbose=False, learning_rate=0.1, epochs=5000, early_stopping=10**-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aefca00-aeef-4b9d-bc2c-613873bab194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99988542e-01, 1.75925809e-06, 3.07022099e-07],\n",
       "       [3.54600131e-05, 9.99904550e-01, 2.82005870e-05],\n",
       "       [1.25291979e-05, 9.99968414e-01, 3.72376468e-05],\n",
       "       [1.41298210e-08, 4.84498088e-05, 9.99949298e-01],\n",
       "       [1.77713480e-08, 1.06144183e-04, 9.99887608e-01],\n",
       "       [9.99984807e-01, 2.27293087e-06, 3.13993455e-07],\n",
       "       [9.99986556e-01, 1.99878721e-06, 3.06387008e-07],\n",
       "       [1.18239020e-06, 2.59005230e-03, 9.97340198e-01],\n",
       "       [1.42753420e-08, 5.01929751e-05, 9.99947437e-01],\n",
       "       [5.90376759e-05, 9.99884667e-01, 3.40452550e-05],\n",
       "       [9.99886990e-01, 1.86539323e-05, 4.71406522e-07],\n",
       "       [4.57510648e-05, 9.99901545e-01, 3.27074045e-05],\n",
       "       [1.49621392e-08, 5.89184745e-05, 9.99938141e-01],\n",
       "       [9.41059424e-05, 9.99869580e-01, 4.22662258e-05],\n",
       "       [1.23573038e-05, 9.99967407e-01, 3.52696987e-05],\n",
       "       [1.42162047e-08, 4.90924981e-05, 9.99948626e-01],\n",
       "       [5.12287426e-07, 9.72222312e-01, 2.90691533e-02],\n",
       "       [2.98433592e-05, 9.99919364e-01, 2.88920055e-05],\n",
       "       [1.22038054e-05, 9.99967323e-01, 3.51417133e-05],\n",
       "       [1.26669212e-05, 9.99965523e-01, 3.36349760e-05],\n",
       "       [1.42522848e-08, 4.92035937e-05, 9.99948539e-01],\n",
       "       [1.54987261e-05, 9.99960998e-01, 3.40692267e-05],\n",
       "       [3.48037893e-06, 9.99999217e-01, 1.14172253e-06],\n",
       "       [4.72797057e-08, 3.39474158e-03, 9.96236432e-01],\n",
       "       [1.45179863e-08, 5.31017002e-05, 9.99944333e-01],\n",
       "       [9.99976156e-01, 3.65229476e-06, 3.43970055e-07],\n",
       "       [1.45384059e-08, 5.29849378e-05, 9.99944435e-01],\n",
       "       [1.69547865e-05, 9.99956313e-01, 3.29323845e-05],\n",
       "       [1.82007983e-05, 9.99950639e-01, 3.11823716e-05],\n",
       "       [1.41528377e-08, 4.86992454e-05, 9.99949030e-01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = model2.predict(X_test)\n",
    "y_pred2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
