{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32dc1b13-52b9-4f13-8ceb-c8da5b58d5c1",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8d5c16-1faf-40b2-b214-abbb84dff942",
   "metadata": {},
   "source": [
    "## Задания\n",
    "\n",
    "Самостоятельно написать код, реализующий искусственный нейрон с сигма-функцией активации, и возможность строить на его основе многослойные сети. Код должен также реализовывать градиентный спуск и обратное распространение ошибки.\n",
    "\n",
    "На основе вашего кода:\n",
    "\n",
    "1. Решить задачу  классификации датаcета Iris одним нейроном.\n",
    "2. Решить задачу  классификации датаcета Iris одним  нейросетью из 2 слоев по 10 нейронов в слое.\n",
    "3. Отрисовать разделяющую линию для обеих моделей. Сравнить метрики классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e874744-dd80-49c2-8fb3-937ee39e9b75",
   "metadata": {},
   "source": [
    "## Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced18f6c-63a0-4d64-98d5-d34949c427ff",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc1fe0b-3c79-40b0-9929-51da56945f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81ddf1-6093-4df9-b5ab-3c367e1549f4",
   "metadata": {},
   "source": [
    "### Сигма-функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba2eb9a-5d71-42a1-9139-e3375a273932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def der_sigmoid(x):  # производная сигма-функции\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc8566-f1b5-4f15-a7c0-acee2340f1c8",
   "metadata": {},
   "source": [
    "### Нейрон\n",
    "\n",
    "Его формула: `y = f(sum_i(w_i*x_i + b_i))`, где:\n",
    "\n",
    "* w - веса\n",
    "* x - входные данные\n",
    "* b - сдвиг\n",
    "* f - функция активации\n",
    "* i - индекс\n",
    "* sum_i - сумма по индексам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d99fb0d9-7ee8-433a-8bbe-32cd73315389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, input_count, default_weight, default_bias):\n",
    "        self.attribute_count = input_count  # кол-во весов и сдвигов равно кол-во вводных данных\n",
    "        self.weights = np.full((1, self.attribute_count), default_weight)  # вектор весов нейрона, при инициализации задаётся значение по умолчанию\n",
    "        self.bias = np.full((1, self.attribute_count), default_bias)  # вектор сдвигов нейрона, при инициализации задаётся значение по умолчанию\n",
    "        self.sum_result = 0\n",
    "        \n",
    "    def output(self, input_values):\n",
    "        self.sum_result = np.sum(np.dot(self.weights, input_values) + self.bias)\n",
    "        return sigmoid(self.sum_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5fd2c8-0636-4309-b841-db0a29e32f14",
   "metadata": {},
   "source": [
    "### Функция ошибки\n",
    "\n",
    "Здесь будет использоваться MSE (Mean Square Error)\n",
    "\n",
    "Её формула: `sum_i((true_i - pred_i)^2) / N`, где:\n",
    "\n",
    "* true - истинные значения\n",
    "* pred - предсказанные значения\n",
    "* i - индекс\n",
    "* N - размер\n",
    "* sum_i - сумма по индексам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50161bd-f875-47be-bf5a-a4e990686329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return ((y_true - y_pred)**2).mean()\n",
    "\n",
    "def der_mse(y_true, y_pred):  # производная функции ошибок (для одного предсказанного значения y_pred)\n",
    "    return -2 * (y_true - y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9dd3c6-6466-4bd4-a646-e87b41e7c55d",
   "metadata": {},
   "source": [
    "### Слой нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef66cdba-e574-4124-be84-7c04deb8791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, neuron_count):\n",
    "        self.neuron_count = neuron_count\n",
    "        self.neurons = []\n",
    "        self.input_count = 0\n",
    "        self.input_values = None\n",
    "\n",
    "    def setup_neurons(self, input_count, default_weight=1, default_bias=0):  # изначальный вес = 1, изначальный свдиг = 0, если не задано иное\n",
    "        if input_count <= 0:\n",
    "            raise ValueError(\"No inputs to this neuron were provided\")\n",
    "\n",
    "        self.input_count = input_count\n",
    "        \n",
    "        for i in range(self.neuron_count):\n",
    "            new_neuron = Neuron(self.input_count, default_weight, default_bias) \n",
    "            self.neurons.append(new_neuron)\n",
    "\n",
    "    def input_output(self, input_values):\n",
    "        if len(input_values) != self.input_count:\n",
    "            raise ValueError(\"The amount of input values doesn't match the amount of inputs for this layer's neurons\")\n",
    "\n",
    "        self.input_values = input_values\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for neuron in self.neurons:\n",
    "            outputs.append(neuron.output(input_values))\n",
    "\n",
    "        return np.array(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ed3db-c3bb-48f9-b13f-b3caef263014",
   "metadata": {},
   "source": [
    "### Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d8896ba-a343-4b00-9d13-cc66327e0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers=[]):\n",
    "        self.layers = layers\n",
    "        self.layer_count = len(self.layers)\n",
    "        self.attribute_count = 0  # кол-во вводимых аттрибутов\n",
    "        self.verbose = False\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.layer_count += 1\n",
    "\n",
    "    def log(self, text):\n",
    "        if self.verbose:\n",
    "            print(text)\n",
    "\n",
    "    def gradient_descent(self, target_neuron, target_layer, cur_neuron, cur_layer):  # рекурсивно считаем градиентный спуск\n",
    "        layer = self.layers[cur_layer]\n",
    "        neuron = layer.neurons[cur_neuron] \n",
    "        der = der_sigmoid(neuron.sum_result)  # значение производной от функции активации этого нейрона\n",
    "\n",
    "        if cur_layer == target_layer and cur_neuron == target_neuron:\n",
    "            return der * layer.input_values, np.fill((1, neuron.attribute_count), der)  # искомый нейрон, производная по весам будет равна вводным данным, а по сдвигам равна 1\n",
    "\n",
    "        if cur_layer - 1 == target_layer:  # если на предыдущем слое находится искомый нейрон, то сразу берём его значение\n",
    "            prev_weight, prev_bias = self.gradient_descent(target_neuron, target_layer, target_neuron, target_layer)\n",
    "            \n",
    "            target_weight = neuron.weights[target_neuron]  # вес, относящийся к искомому нейрону, остальные веса не нужны, т.к. производные по нейронам, к которым они относятся, будут равны 0\n",
    "            \n",
    "            return der * target_weight * prev_weight, der * target_weight\n",
    "\n",
    "        weight, bias = np.zeros((1, neuron.attribute_count)), np.zeros((1, neuron.attribute_count))\n",
    "        \n",
    "        for prev_neuron in range(self.layers[cur_layer - 1]):  # если же на предыдущем слое нету искомого нейрона, то суммируем все произведения весов на производные\n",
    "            prev_weight, prev_bias = self.gradient_descent(target_neuron, target_layer, prev_neuron, cur_layer - 1)\n",
    "\n",
    "            neuron_weight = neuron.weights[prev_neuron]  # вес, относящийся к предыдущему нейрону\n",
    "\n",
    "            weight += prev_weight * neuron_weight\n",
    "            bias += prev_bias * neuron_weight\n",
    "            \n",
    "        return der * weight, der * bias\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_test, y_test, learning_speed=0.1, epochs=200, early_stopping=None, verbose=False):\n",
    "        if len(X_train) != len(y_train) or len(X_test) != len(y_test):\n",
    "            raise ValueError(\"X and y must be the same size\")\n",
    "            \n",
    "        if self.layers[-1].neuron_count != 1:\n",
    "            raise ValueError(\"No dense layer at the end was provided\")\n",
    "\n",
    "        if learning_speed <= 0:\n",
    "            raise ValueError(\"Learning speed must be more than 0\")\n",
    "\n",
    "        self.attribute_count = len(X_train[0])\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Инициализация каждого слоя\n",
    "\n",
    "        for layer in range(self.layer_count):\n",
    "            self.log(f\"Initialising layer {layer+1} out of {self.layer_count}\")\n",
    "            \n",
    "            if layer == 0:\n",
    "                self.layers[layer].setup_neurons(input_count=self.attribute_count)  # первый слой - входной, у него кол-во входных данных равно кол-ву вводимых атрибутов\n",
    "\n",
    "            else:\n",
    "                self.layers[layer].setup_neurons(input_count=self.layers[layer-1].neutron_count)  # у каждого последующего слоя кол-во входных данных равно кол-ву нейронов на предыдущем слое\n",
    "\n",
    "        train_value_count = len(X_train)\n",
    "\n",
    "        # Начинаем обучение\n",
    "\n",
    "        last_error = None\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.log(f\"Epoch {epoch+1} out of {epochs}\")\n",
    "            y_pred = []  # предсказанные значения\n",
    "            \n",
    "            for value in range(train_value_count):\n",
    "                self.log(f\"Predicting for train value {value+1} out of {train_value_count}\")\n",
    "                \n",
    "                neuron_output = X_train[value]\n",
    "\n",
    "                for layer in range(self.layer_count):\n",
    "                    self.log(f\"Getting input/output for layer {layer+1} out of {self.layer_count}\")\n",
    "                    \n",
    "                    neuron_output = self.layers[layer].input_output(neuron_output)\n",
    "\n",
    "                y_pred.append(neuron_output)  # значение последнего слоя и будет предсказанным значением\n",
    "\n",
    "            y_pred = np.array(y_pred)  # получили предсказание\n",
    "            error = mse(y_train, y_pred)  # значение ошибки\n",
    "            self.log(f\"Predicting done, current error is {error}\")\n",
    "\n",
    "            if early_stopping is not None:  # early_stopping - это минимальная разница в ошибке, после которой можно остановиться\n",
    "                if last_error is not None:\n",
    "                    if abs(error - last_error) < early_stopping:\n",
    "                        break\n",
    "                \n",
    "                last_error = error\n",
    "\n",
    "            # Теперь выполняем градиентный спуск\n",
    "\n",
    "            last_neuron, last_layer = 1, self.layer_count-1  # градиентный спуск идёт с конца\n",
    "\n",
    "            for value in range(train_value_count):\n",
    "                der_loss = der_mse(y_train[value], y_pred[value])  # производная функции ошибок\n",
    "                \n",
    "                for layer in range(self.layer_count):\n",
    "                    cur_layer = self.layers[layer]\n",
    "                    \n",
    "                    for neuron in range(cur_layer.neuron_count):\n",
    "                        cur_neuron = cur_layer.neurons[neuron]\n",
    "                        \n",
    "                        self.log(f\"Gradient descent for NEURON {neuron+1} out of {cur_layer.neuron_count} for LAYER {layer+1} out of {self.layer_count} for VALUE {value+1} out of {train_value_count}\")\n",
    "    \n",
    "                        weight_descent, bias_descent = self.gradient_descent(neuron, layer, last_neuron, last_layer)\n",
    "                        \n",
    "                        cur_neuron.weights -= weight_descent * learning_speed * der_loss  # изменение весов нейрона по результатам спуска\n",
    "                        cur_neuron.bias -= bias_descent * learning_speed * der_loss  # изменение сдвигов нейрона по результатам спуска\n",
    "\n",
    "        # Теперь начинаем предсказание\n",
    "\n",
    "        y_pred = []  # предсказанные значения\n",
    "        test_value_count = len(X_test)\n",
    "\n",
    "        for value in range(test_value_count):\n",
    "            self.log(f\"Predicting for test value {value+1} out of {test_value_count}\")\n",
    "            \n",
    "            neuron_output = X_test[value]\n",
    "\n",
    "            for layer in range(self.layer_count):\n",
    "                self.log(f\"Getting input/output for layer {layer+1} out of {self.layer_count}\")\n",
    "                \n",
    "                neuron_output = self.layers[layer].input_output(neuron_output)\n",
    "\n",
    "            y_pred.append(neuron_output)  # значение последнего слоя и будет предсказанным значением\n",
    "\n",
    "        return np.array(y_pred)  # получили предсказание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b2436a-82d4-4aec-ac3f-4cf12e3f86cb",
   "metadata": {},
   "source": [
    "Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d494681-d500-4fac-845a-61b4417d5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_iris()\n",
    "X, y = df[\"data\"], df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63b78b-0254-4f21-a51c-849b7f09e859",
   "metadata": {},
   "source": [
    "### Деление датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "826db822-be24-4ddb-840d-582dcc88f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, split=0.2):\n",
    "    if split > 1 or split < 0:\n",
    "        raise ValueError(\"train_test split must be within [0, 1]\")\n",
    "    \n",
    "    split_index = int(len(X)*split)\n",
    "    return np.array(X[split_index:]), np.array(y[split_index:]), np.array(X[:split_index]), np.array(y[:split_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e969371d-90ce-4e61-8d59-d249ef9a6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
