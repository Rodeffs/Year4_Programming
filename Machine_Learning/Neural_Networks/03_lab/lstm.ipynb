{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882db8db-7f7f-4b1c-812f-11dcfc714fea",
   "metadata": {},
   "source": [
    "# Лабораторная работа №3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94ece4-f71a-43d5-9757-e991b59f534b",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "Создать сеть на базе LSTM используя TensorFlow (Keras). Сеть должна принимать на вход текстовый файл и на его базе генерировать свою абракадабру. Отчет должен содержать кроме кода, обучающий файл и результат генерации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0e3a4-11fd-40c5-be1d-382a595230ca",
   "metadata": {},
   "source": [
    "## Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0e317-66b8-4226-827b-966ab1fd55c7",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d519efb6-f26a-4438-b84b-4534ac1c57af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 00:44:53.837953: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/owner/.python_env/local/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02581ba3-6b47-4b0c-95ac-33ae9fd3d581",
   "metadata": {},
   "source": [
    "### Датасет\n",
    "\n",
    "В качестве датасета возьмём произведение Моби Дик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fab1433-c561-4cb3-a40b-970f2c261876",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"moby_dick.txt\", mode=\"r\", encoding=\"utf-8-sig\")  # sig нужен чтобы убрать кодировку в начале текста\n",
    "text = file.read().replace(\"\\n\", \" \")  # убираем лишние переносы и преобразуем всё в одну строку\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7209d3d-d319-4853-a911-efd0c58dc6bd",
   "metadata": {},
   "source": [
    "### Токенезация (векторизация) слов\n",
    "\n",
    "LSTM работает только с числами. Чтобы она смогла работать с текстом, слова в нём нужно токенезировать.\n",
    "\n",
    "Для этого в Keras уже есть слой TextVectorization. Через него уберём пунктуацию, поделим слова по пробелам и выведем всё в виде целых чисел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e7c877-699c-449f-82fc-64a95a1251f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1766529896.669046  150738 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1059 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "vectoriser = layers.TextVectorization(standardize='lower_and_strip_punctuation', split='whitespace', output_mode='int')\n",
    "vectoriser.adapt(text)\n",
    "max_tokens = len(vectoriser.get_vocabulary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e09e79-d376-4cfd-a4a9-276b18e005cd",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a58ee74-f10a-4b80-9f62-a02f3792aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128  # embedding переводит вывод моего токенезатора в плотный вектор признаков, его размерность будет max_tokens x embedding_dim\n",
    "lstm_units = 256  # параметр показывает, как много признаков запоминает модель и как хорошо улавливает контекст\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=max_tokens, output_dim=embedding_dim, mask_zero=True),  # mask_zero чтобы все слои поддерживали masking\n",
    "    layers.LSTM(units=lstm_units),\n",
    "    layers.Dense(units=max_tokens, activation=\"softmax\")  # именно он и будет предсказывать следующий токен\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe996be-e6f8-4f82-8323-3b2143d343d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')  # именно такая функция потерь, т.к. здесь много классов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f485c3a6-2556-46e7-9b00-9e3f7ddbccfc",
   "metadata": {},
   "source": [
    "### Скользящее окно для обучающих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc32d7c6-a929-48c8-acdc-f2ee545f6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorised_text = vectoriser(text)\n",
    "\n",
    "X, y = [], []\n",
    "window_size = 20  # сколько слов модель запоминает, чтобы предказать следующее\n",
    "\n",
    "for i in range(0, len(vectorised_text) - window_size, window_size):\n",
    "    X.append(vectorised_text[i:i+window_size])\n",
    "    y.append(vectorised_text[i+window_size])\n",
    "\n",
    "X = tf.stack(X)\n",
    "y = tf.stack(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c6b066-0d06-4737-af6e-da2e565c4b3c",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde4f964-922f-4d13-abae-0e246fcbbe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 00:45:05.277713: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 7.6810\n",
      "Epoch 2/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 6.6365\n",
      "Epoch 3/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 6.3760\n",
      "Epoch 4/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 6.1243\n",
      "Epoch 5/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 5.8963\n",
      "Epoch 6/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 5.6791\n",
      "Epoch 7/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 5.4662\n",
      "Epoch 8/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 5.2723\n",
      "Epoch 9/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 5.0750\n",
      "Epoch 10/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 4.9116\n",
      "Epoch 11/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 4.6547\n",
      "Epoch 12/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 4.4084\n",
      "Epoch 13/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 4.1849\n",
      "Epoch 14/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.9372\n",
      "Epoch 15/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 3.6934\n",
      "Epoch 16/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 3.4409\n",
      "Epoch 17/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 3.1867\n",
      "Epoch 18/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 2.9361\n",
      "Epoch 19/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 2.6861\n",
      "Epoch 20/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 2.4490\n",
      "Epoch 21/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 2.2089\n",
      "Epoch 22/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 1.9861\n",
      "Epoch 23/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 1.7637\n",
      "Epoch 24/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.5709\n",
      "Epoch 25/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 1.3794\n",
      "Epoch 26/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 1.2165\n",
      "Epoch 27/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 1.0648\n",
      "Epoch 28/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.9299\n",
      "Epoch 29/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.8109\n",
      "Epoch 30/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.6973\n",
      "Epoch 31/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.6030\n",
      "Epoch 32/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.5148\n",
      "Epoch 33/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.4434\n",
      "Epoch 34/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.3738\n",
      "Epoch 35/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3265\n",
      "Epoch 36/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2906\n",
      "Epoch 37/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2253\n",
      "Epoch 39/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1966\n",
      "Epoch 40/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1525\n",
      "Epoch 41/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1278\n",
      "Epoch 42/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1130\n",
      "Epoch 43/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0913\n",
      "Epoch 44/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0747\n",
      "Epoch 45/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0598\n",
      "Epoch 46/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0521\n",
      "Epoch 47/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0492\n",
      "Epoch 48/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0684\n",
      "Epoch 49/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1601\n",
      "Epoch 50/50\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f65edae2900>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42961c8-0232-4502-869d-ed3aede3ec2b",
   "metadata": {},
   "source": [
    "### Генерация слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f645802c-f39e-4d49-8e0c-9ad5594cc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(probabilities, temperature=0.8):  # это нам поможет брать не самое вероятное слово на каждом шаге, а слегка другие, чтобы вывод не зацикливался\n",
    "    probabilities = np.asarray(probabilities).astype(\"float64\")\n",
    "    probabilities = probabilities[2:]  # 2 здесь нужна, т.к. первые два индекса в словаре не несут значения\n",
    "\n",
    "    probabilities = np.log(probabilities + 1e-9) / temperature  # 10^-9 было добавлено во избежание 0 в логарифме\n",
    "\n",
    "    exp_probs = np.exp(probabilities)  # возвели в экспоненту, тем самым перешли от логарифма опять к вероятностям\n",
    "    probabilities = exp_probs / np.sum(exp_probs)\n",
    "\n",
    "    return np.random.choice(max_tokens-2, p=probabilities)+2  # вернули 2 чтобы не выбрать случайно первые 2 индекса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e415fc4c-d2e2-494d-abb0-4ede282730aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, vectoriser, input_text, num_words):\n",
    "    tokens = vectoriser([input_text])\n",
    "    output_text = input_text\n",
    "\n",
    "    for i in range(num_words):\n",
    "        preds = model.predict(tokens, verbose=0)  # выведет вероятность каждого слова\n",
    "        next_id = sample(preds[0])  # выбирает индекс слова исходя из вероятности и небольшой случайности, определяемой температурой\n",
    "        next_word = vectoriser.get_vocabulary()[next_id]  # возвращает слово по индексу\n",
    "\n",
    "        output_text += \" \" + next_word\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37338d97-7a21-4b46-a64a-c5fafbda74be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what noiseless northward scuttle chin american unlacing fast masterless leeward embalmed versions charge fool snowshoes harpooneers noiseless rude green porch seethings scuttle fashioned added terrific period nursing lean grimness vicinity street rot death stroll work felonious forefinger final merchant sun vicinity extreme rosewater sheetiron cleansed remaining oar pursuit disjointedly floorscrewed howl paddling wreck czar whose splash flume pipe binnacle hidden pyramid mother folio ivory—oh snowline lookout bison sudden dimly squall elasticity potatoes “shark” mind log justly period noiseless faraway nantucket transferred chimney scuttle cities afflictions vicinity stake horizontal grim land elbowed scuttle food reckless tragic starry bitterest mind hurried certain carpenter\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, vectoriser, \"what\", 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
