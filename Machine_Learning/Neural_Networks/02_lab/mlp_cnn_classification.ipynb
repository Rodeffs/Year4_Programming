{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24797504-94bf-42e7-93e1-e8f9cb59854b",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a409828a-a0de-4e37-9dd9-e74b68f0d5c3",
   "metadata": {},
   "source": [
    "## Задания\n",
    "\n",
    "Решить задачу классификации датасета MNIST используя MLP из scikitlearn и используя CNN (по типу LeNet) c пакетом PyTorch. Сравнить результаты по метрикам, сделать обоснованные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b51dd9-8f5f-4f96-83c8-ec600741bfc7",
   "metadata": {},
   "source": [
    "## Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8851b6-b522-454e-a830-5f0334825cec",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0a6e8b-b750-4d91-b8be-98e23c01c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7dd596-7e43-4938-a7c0-f549cdbf4735",
   "metadata": {},
   "source": [
    "### Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859021c4-fe42-43b7-ab3e-e3d1e0a40741",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "y = y.astype(np.int64)  # т.к. там классификация цифр, то лучше если брать по числовому значению\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)  # stratify нужен, чтобы все классы были так или иначе включены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20037a29-a31e-42ee-b750-e188f60ff8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_transform(y, classes_count):  # преобразование в матрицу вхождений\n",
    "    transformed = np.zeros((len(y), classes_count))\n",
    "\n",
    "    for i in range(len(y)):  # исходит из предположения, что классы будут пронумерованы по порядку, начиная от 0\n",
    "        transformed[i][y[i]] = 1\n",
    "\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b02585-0e38-4299-a40e-570a65ad1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = one_hot_transform(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a533575-e3bb-4608-bdb9-be4b11d34746",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06444800-6a09-43a9-9a9c-59e90deb3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(early_stopping=True).fit(X_train, y_train)  # early stopping чтобы не ждать слишком долго"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59151fbb-8ad7-4a4b-8c73-22b8b5229259",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mlp_proba = clf.predict_proba(X_test)\n",
    "y_mlp = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e33db2-67bd-4227-b406-c3e58213c4df",
   "metadata": {},
   "source": [
    "### LeNet (Convolutional Neural Network)\n",
    "\n",
    "LeNet состоит из следующих слоёв:\n",
    "\n",
    "1. Входной слой: изображение 28x28 пикселей, 1 канал\n",
    "2. Свёрточный слой: ядро 5x5, padding 2, 6 каналов на выходе, функция активации - гиперболический тангенс\n",
    "3. AvgPooling: ядро 2x2, stride 2\n",
    "4. Свёрточный слой: ядро 5x5, 16 каналов на выходе, функция активации - гиперболический тангенс\n",
    "5. AvgPooling: ядро 2x2, stride 2\n",
    "6. Уплотнение\n",
    "7. Плотный слой из 120 нейронов, функция активации - гиперболический тангенс\n",
    "8. Плотный слой из 84 нейронов, функция активации - гиперболический тангенс\n",
    "9. Выходной (плотный) слой из 10 нейронов (т.к. цифры от 0 до 9)\n",
    "\n",
    "Padding нужен для того, чтобы улавливать более тонкие детали - вроде углов картинок. Если бы входное изображение было размером 32x32, то тогда в padding не было бы нужды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "830be849-79e1-43cd-861e-e237e98145cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # Свёрточный слой 1\n",
    "        # Было изображение 28x28x1, стало 28x28x6, размер не уменьшился т.к. padding добавил к каждой стороне 2\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2) \n",
    "\n",
    "        # Свёрточный слой 2\n",
    "        # Был mapping 14x14x6, стал 10x10x16, как видно, размер уменьшился\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "\n",
    "        # AvgPooling\n",
    "        # Уменьшает размер в 2 раза, т.к. stride = 2 (stride = размерность \"куска\" для пулинга)\n",
    "        # Пример: картинку 10x10 просканировали квадратом 2x2 и взяли среднее в этом квадрате, на выходе получится картинка 5x5)\n",
    "\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Плотный слой 1\n",
    "        # 400 т.к. после pooling будут мэппинги размером 5x5 и их будет 16 штук, т.е. 5*5*16=400\n",
    "        \n",
    "        self.dense1 = nn.Linear(in_features=400, out_features=120) \n",
    "\n",
    "        # Плотный слой 2\n",
    "\n",
    "        self.dense2 = nn.Linear(in_features=120, out_features=84)\n",
    "\n",
    "        # Плотный слой 3 (выходной)\n",
    "\n",
    "        self.dense3 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "        # Функция активации\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x):  # теперь определяем порядок выполнения\n",
    "        out = self.conv1(x)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.pool(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.pool(out)\n",
    "        out = torch.flatten(out, start_dim=1)  # уплотняем\n",
    "        \n",
    "        out = self.dense1(out)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.dense2(out)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.dense3(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85726776-cd86-4ec3-a9e5-e0868e8c68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # чтобы быстрее обучалось, использую cuda\n",
    "lenet = LeNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40da0c-ed64-4a87-b426-fa6a6db43b0a",
   "metadata": {},
   "source": [
    "### Нормализация данных\n",
    "\n",
    "Необходимо для корректного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c9fff4-1088-454c-8c8d-afe9ed1bf718",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.1307  # уже просчитанные значения для этого датасета\n",
    "std = 0.3081\n",
    "\n",
    "images_train = (X_train/255 - mean)/std\n",
    "images_test = (X_test/255 - mean)/std\n",
    "\n",
    "images_train = images_train.reshape(-1, 1, 28, 28)\n",
    "images_test = images_test.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e81ca9-0a01-42c9-8712-68ce38ec5319",
   "metadata": {},
   "source": [
    "### Преобразование датасета\n",
    "\n",
    "PyTorch требует, чтобы датасет был определённого формата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dc44cdb-dde6-43fd-8d30-9d69badf1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.tensor(images_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "test_dataset = TensorDataset(torch.tensor(images_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e7970-d960-40c3-8b75-a683e470003d",
   "metadata": {},
   "source": [
    "### Обучение LeNet\n",
    "\n",
    "Теперь определяем, как будет обучаться модель. Для этого нужна функция ошибок и оптимизатор (Adam или градиентный спуск)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d735c083-a197-4e73-a2e8-8d772353b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(lenet.parameters(), lr=10**-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0ccfa58-492f-4672-8dcf-b31b83d1bdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 10, loss is 0.3550818792913662\n",
      "Epoch 2 out of 10, loss is 0.09999014626182344\n",
      "Epoch 3 out of 10, loss is 0.0647959651679272\n",
      "Epoch 4 out of 10, loss is 0.0491717707710182\n",
      "Epoch 5 out of 10, loss is 0.037563357588329745\n",
      "Epoch 6 out of 10, loss is 0.03041205348825386\n",
      "Epoch 7 out of 10, loss is 0.02415721211922321\n",
      "Epoch 8 out of 10, loss is 0.020599473506289278\n",
      "Epoch 9 out of 10, loss is 0.01733624787634089\n",
      "Epoch 10 out of 10, loss is 0.01633281289662717\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 10\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = lenet(images)\n",
    "        loss = cost(outputs, labels)\n",
    "        \n",
    "        optimiser.zero_grad()  # обнулить градиенты\n",
    "        loss.backward()\n",
    "        optimiser.step()  # провести оптимизацию\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} out of {total_epochs}, loss is {running_loss/len(train_loader)}\")  # делим,т.к. running_loss - это сумма ошибки каждого батча, а не модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397b224-c89d-4ced-b32f-6499c7fe2d4e",
   "metadata": {},
   "source": [
    "### Предсказание LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef63a359-1bfd-4738-8cbd-5585110daa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.eval()  # переводим в режим оценки\n",
    "\n",
    "y_net_proba = []\n",
    "y_net =[]\n",
    "\n",
    "with torch.no_grad():  # уменьшить потребление памяти\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = lenet(images)\n",
    "\n",
    "        probs = torch.softmax(outputs, dim=1)  # вероятности\n",
    "\n",
    "        for proba in probs.cpu().numpy():  \n",
    "            y_net_proba.append(proba)\n",
    "\n",
    "        for label in outputs.argmax(dim=1).cpu().numpy():  # предсказанные классы\n",
    "            y_net.append(label)\n",
    "\n",
    "y_net_proba = np.array(y_net_proba)\n",
    "y_net = np.array(y_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6098b9da-7d4c-48d5-9bae-50ab169e8c09",
   "metadata": {},
   "source": [
    "### Метрики MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13a8d391-c6f7-4e01-b95c-f0d2b92b2811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7198083-9ba6-4761-9779-2aa0f3f9973a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9637370570049193"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_mlp, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e372a12-4736-4908-b93a-71c7454a92db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9638747294852854"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_mlp, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eab3e4d-592e-4971-a270-ff7b770ea021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9636953445317215"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_mlp, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8874b827-bd65-4a16-a863-1dc1533e5802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9980145358515617"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_proba, y_mlp_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa4da8a-abbb-435e-bd11-c76e86b84f45",
   "metadata": {},
   "source": [
    "### Метрики LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa088d9d-11b5-4ba8-b199-e09a02e67a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b79be49-c1a1-4add-b20b-0e66920cbc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863082778861536"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_net, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d503be54-4124-4946-8e94-69611e94ea5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863085085595529"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_net, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d09b9dee-810b-4ed7-93f0-6427b1032efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9862861736112171"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_net, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c5bb991-ff0b-4707-96aa-08536f56646e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997987418015242"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_proba, y_net_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397cb6a-e414-4ff2-9c25-b652b70831c6",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "По результатам метрик можно сделать вывод, что LeNet лучше может определить, к какому типу относится картинка\n",
    "\n",
    "Обе модели хорошо умеют отличать классы друг от друга, но LeNet всё же точнее MLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
