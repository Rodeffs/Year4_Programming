{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24797504-94bf-42e7-93e1-e8f9cb59854b",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a409828a-a0de-4e37-9dd9-e74b68f0d5c3",
   "metadata": {},
   "source": [
    "## Задания\n",
    "\n",
    "Решить задачу классификации датасета MNIST используя MLP из scikitlearn и используя CNN (по типу LeNet) c пакетом PyTorch. Сравнить результаты по метрикам, сделать обоснованные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b51dd9-8f5f-4f96-83c8-ec600741bfc7",
   "metadata": {},
   "source": [
    "## Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8851b6-b522-454e-a830-5f0334825cec",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0a6e8b-b750-4d91-b8be-98e23c01c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7dd596-7e43-4938-a7c0-f549cdbf4735",
   "metadata": {},
   "source": [
    "### Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859021c4-fe42-43b7-ab3e-e3d1e0a40741",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "y = y.astype(np.int64)  # т.к. там классификация цифр, то лучше если брать по числовому значению\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)  # stratify нужен, чтобы все классы были так или иначе включены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20037a29-a31e-42ee-b750-e188f60ff8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_transform(y, classes_count):  # преобразование в матрицу вхождений\n",
    "    transformed = np.zeros((len(y), classes_count))\n",
    "\n",
    "    for i in range(len(y)):  # исходит из предположения, что классы будут пронумерованы по порядку, начиная от 0\n",
    "        transformed[i][y[i]] = 1\n",
    "\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b02585-0e38-4299-a40e-570a65ad1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = one_hot_transform(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a533575-e3bb-4608-bdb9-be4b11d34746",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06444800-6a09-43a9-9a9c-59e90deb3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(early_stopping=True).fit(X_train, y_train)  # early stopping чтобы не ждать слишком долго"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59151fbb-8ad7-4a4b-8c73-22b8b5229259",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mlp_proba = clf.predict_proba(X_test)\n",
    "y_mlp = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e33db2-67bd-4227-b406-c3e58213c4df",
   "metadata": {},
   "source": [
    "### LeNet (Convolutional Neural Network)\n",
    "\n",
    "LeNet состоит из следующих слоёв:\n",
    "\n",
    "1. Входной слой: изображение 28x28 пикселей, 1 канал\n",
    "2. Свёрточный слой: ядро 5x5, padding 2, 6 каналов на выходе, функция активации - гиперболический тангенс\n",
    "3. AvgPooling: ядро 2x2, stride 2\n",
    "4. Свёрточный слой: ядро 5x5, 16 каналов на выходе, функция активации - гиперболический тангенс\n",
    "5. AvgPooling: ядро 2x2, stride 2\n",
    "6. Уплотнение\n",
    "7. Плотный слой из 120 нейронов, функция активации - гиперболический тангенс\n",
    "8. Плотный слой из 84 нейронов, функция активации - гиперболический тангенс\n",
    "9. Выходной (плотный) слой из 10 нейронов (т.к. цифры от 0 до 9)\n",
    "\n",
    "Padding нужен для того, чтобы улавливать более тонкие детали - вроде углов картинок. Если бы входное изображение было размером 32x32, то тогда в padding не было бы нужды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "830be849-79e1-43cd-861e-e237e98145cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # Свёрточный слой 1\n",
    "        # Было изображение 28x28x1, стало 28x28x6, размер не уменьшился т.к. padding добавил к каждой стороне 2\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2) \n",
    "\n",
    "        # Свёрточный слой 2\n",
    "        # Был mapping 14x14x6, стал 10x10x16, как видно, размер уменьшился\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "\n",
    "        # AvgPooling\n",
    "        # Уменьшает размер в 2 раза, т.к. stride = 2 (stride = размерность \"куска\" для пулинга)\n",
    "        # Пример: картинку 10x10 просканировали квадратом 2x2 и взяли среднее в этом квадрате, на выходе получится картинка 5x5)\n",
    "\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Плотный слой 1\n",
    "        # 400 т.к. после pooling будут мэппинги размером 5x5 и их будет 16 штук, т.е. 5*5*16=400\n",
    "        \n",
    "        self.dense1 = nn.Linear(in_features=400, out_features=120) \n",
    "\n",
    "        # Плотный слой 2\n",
    "\n",
    "        self.dense2 = nn.Linear(in_features=120, out_features=84)\n",
    "\n",
    "        # Плотный слой 3 (выходной)\n",
    "\n",
    "        self.dense3 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "        # Функция активации\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x):  # теперь определяем порядок выполнения\n",
    "        out = self.conv1(x)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.pool(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.pool(out)\n",
    "        out = torch.flatten(out, start_dim=1)  # уплотняем\n",
    "        \n",
    "        out = self.dense1(out)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.dense2(out)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.dense3(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "85726776-cd86-4ec3-a9e5-e0868e8c68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # чтобы быстрее обучалось, использую cuda\n",
    "lenet = LeNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e81ca9-0a01-42c9-8712-68ce38ec5319",
   "metadata": {},
   "source": [
    "### Преобразование датасета\n",
    "\n",
    "PyTorch требует, чтобы датасет был определённого формата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7dc44cdb-dde6-43fd-8d30-9d69badf1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация\n",
    "\n",
    "mean_values = X_train.mean(axis=0)\n",
    "max_min_values = X_train.max(axis=0) - X_train.min(axis=0)\n",
    "\n",
    "images_train = np.zeros(X_train.shape)\n",
    "images_test = np.zeros(X_test.shape)\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    if max_min_values[i] != 0:\n",
    "        images_train[:, i] = (X_train[:, i] - mean_values[i]) / max_min_values[i]\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    if max_min_values[i] != 0:\n",
    "        images_test[:, i] = (X_test[:, i] - mean_values[i]) / max_min_values[i]\n",
    "\n",
    "# Преобразования\n",
    "\n",
    "images_train = images_train.reshape(-1, 1, 28, 28)\n",
    "images_test = images_test.reshape(-1, 1, 28, 28)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(images_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "test_dataset = TensorDataset(torch.tensor(images_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e7970-d960-40c3-8b75-a683e470003d",
   "metadata": {},
   "source": [
    "### Обучение LeNet\n",
    "\n",
    "Теперь определяем, как будет обучаться модель. Для этого нужна функция ошибок и оптимизатор (Adam или градиентный спуск)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d735c083-a197-4e73-a2e8-8d772353b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(lenet.parameters(), lr=5*10**-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0ccfa58-492f-4672-8dcf-b31b83d1bdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 200, loss is 833.4421353340149\n",
      "Epoch 2 out of 200, loss is 328.73681727051735\n",
      "Epoch 3 out of 200, loss is 212.82951891422272\n",
      "Epoch 4 out of 200, loss is 175.90563575923443\n",
      "Epoch 5 out of 200, loss is 155.26011857390404\n",
      "Epoch 6 out of 200, loss is 141.89639949798584\n",
      "Epoch 7 out of 200, loss is 131.6433602720499\n",
      "Epoch 8 out of 200, loss is 123.98127879202366\n",
      "Epoch 9 out of 200, loss is 115.70006880164146\n",
      "Epoch 10 out of 200, loss is 109.27720361948013\n",
      "Epoch 11 out of 200, loss is 103.00877567380667\n",
      "Epoch 12 out of 200, loss is 97.57336025685072\n",
      "Epoch 13 out of 200, loss is 92.24848940968513\n",
      "Epoch 14 out of 200, loss is 87.46432833373547\n",
      "Epoch 15 out of 200, loss is 82.76759923249483\n",
      "Epoch 16 out of 200, loss is 78.67767161875963\n",
      "Epoch 17 out of 200, loss is 74.62776070833206\n",
      "Epoch 18 out of 200, loss is 71.04065188765526\n",
      "Epoch 19 out of 200, loss is 67.46695790998638\n",
      "Epoch 20 out of 200, loss is 64.40154929086566\n",
      "Epoch 21 out of 200, loss is 61.272392980754375\n",
      "Epoch 22 out of 200, loss is 58.52714738994837\n",
      "Epoch 23 out of 200, loss is 55.984699584543705\n",
      "Epoch 24 out of 200, loss is 53.27098373696208\n",
      "Epoch 25 out of 200, loss is 51.304242093116045\n",
      "Epoch 26 out of 200, loss is 49.51844119653106\n",
      "Epoch 27 out of 200, loss is 47.15285548940301\n",
      "Epoch 28 out of 200, loss is 45.4619971588254\n",
      "Epoch 29 out of 200, loss is 43.808563040569425\n",
      "Epoch 30 out of 200, loss is 42.392936777323484\n",
      "Epoch 31 out of 200, loss is 40.95352618768811\n",
      "Epoch 32 out of 200, loss is 39.67525606788695\n",
      "Epoch 33 out of 200, loss is 38.36866955459118\n",
      "Epoch 34 out of 200, loss is 37.34197925403714\n",
      "Epoch 35 out of 200, loss is 36.329279746860266\n",
      "Epoch 36 out of 200, loss is 35.308729691430926\n",
      "Epoch 37 out of 200, loss is 34.276129404082894\n",
      "Epoch 38 out of 200, loss is 33.4896854814142\n",
      "Epoch 39 out of 200, loss is 32.41267281305045\n",
      "Epoch 40 out of 200, loss is 31.735252290032804\n",
      "Epoch 41 out of 200, loss is 31.02080278005451\n",
      "Epoch 42 out of 200, loss is 30.284492570906878\n",
      "Epoch 43 out of 200, loss is 29.541936236433685\n",
      "Epoch 44 out of 200, loss is 29.02965628914535\n",
      "Epoch 45 out of 200, loss is 28.38112616725266\n",
      "Epoch 46 out of 200, loss is 27.767852385528386\n",
      "Epoch 47 out of 200, loss is 27.17883998528123\n",
      "Epoch 48 out of 200, loss is 26.590400556102395\n",
      "Epoch 49 out of 200, loss is 26.17534825578332\n",
      "Epoch 50 out of 200, loss is 25.810389985796064\n",
      "Epoch 51 out of 200, loss is 25.254595901351422\n",
      "Epoch 52 out of 200, loss is 24.816914820112288\n",
      "Epoch 53 out of 200, loss is 24.299330337904394\n",
      "Epoch 54 out of 200, loss is 24.096914232708514\n",
      "Epoch 55 out of 200, loss is 23.724746781401336\n",
      "Epoch 56 out of 200, loss is 23.11885921191424\n",
      "Epoch 57 out of 200, loss is 22.712402995675802\n",
      "Epoch 58 out of 200, loss is 22.54789384547621\n",
      "Epoch 59 out of 200, loss is 22.036203884053975\n",
      "Epoch 60 out of 200, loss is 21.88690610602498\n",
      "Epoch 61 out of 200, loss is 21.407679098192602\n",
      "Epoch 62 out of 200, loss is 21.01730929547921\n",
      "Epoch 63 out of 200, loss is 20.724152237176895\n",
      "Epoch 64 out of 200, loss is 20.510545881465077\n",
      "Epoch 65 out of 200, loss is 19.970536660635844\n",
      "Epoch 66 out of 200, loss is 19.931810622103512\n",
      "Epoch 67 out of 200, loss is 19.53466059686616\n",
      "Epoch 68 out of 200, loss is 19.251799358986318\n",
      "Epoch 69 out of 200, loss is 18.945742048323154\n",
      "Epoch 70 out of 200, loss is 18.912367280572653\n",
      "Epoch 71 out of 200, loss is 18.462354184128344\n",
      "Epoch 72 out of 200, loss is 18.371001944411546\n",
      "Epoch 73 out of 200, loss is 17.978559288661927\n",
      "Epoch 74 out of 200, loss is 17.66475636418909\n",
      "Epoch 75 out of 200, loss is 17.44896209333092\n",
      "Epoch 76 out of 200, loss is 17.26976096816361\n",
      "Epoch 77 out of 200, loss is 16.88666770560667\n",
      "Epoch 78 out of 200, loss is 16.8213646360673\n",
      "Epoch 79 out of 200, loss is 16.520473909564316\n",
      "Epoch 80 out of 200, loss is 16.281943215057254\n",
      "Epoch 81 out of 200, loss is 16.141116469632834\n",
      "Epoch 82 out of 200, loss is 15.856927879154682\n",
      "Epoch 83 out of 200, loss is 15.775617307517678\n",
      "Epoch 84 out of 200, loss is 15.416845642961562\n",
      "Epoch 85 out of 200, loss is 15.265966283157468\n",
      "Epoch 86 out of 200, loss is 15.022846608189866\n",
      "Epoch 87 out of 200, loss is 14.859842240810394\n",
      "Epoch 88 out of 200, loss is 14.65742954518646\n",
      "Epoch 89 out of 200, loss is 14.53631382342428\n",
      "Epoch 90 out of 200, loss is 14.295502117602155\n",
      "Epoch 91 out of 200, loss is 14.143465955741704\n",
      "Epoch 92 out of 200, loss is 13.934817418921739\n",
      "Epoch 93 out of 200, loss is 13.781672325450927\n",
      "Epoch 94 out of 200, loss is 13.597599311033264\n",
      "Epoch 95 out of 200, loss is 13.485762954456732\n",
      "Epoch 96 out of 200, loss is 13.17981794453226\n",
      "Epoch 97 out of 200, loss is 13.254260721616447\n",
      "Epoch 98 out of 200, loss is 12.922771109035239\n",
      "Epoch 99 out of 200, loss is 12.721968429395929\n",
      "Epoch 100 out of 200, loss is 12.673078002640978\n",
      "Epoch 101 out of 200, loss is 12.552241418277845\n",
      "Epoch 102 out of 200, loss is 12.487772092223167\n",
      "Epoch 103 out of 200, loss is 12.197928566485643\n",
      "Epoch 104 out of 200, loss is 12.06936875754036\n",
      "Epoch 105 out of 200, loss is 11.903529887786135\n",
      "Epoch 106 out of 200, loss is 11.685454140068032\n",
      "Epoch 107 out of 200, loss is 11.67616260331124\n",
      "Epoch 108 out of 200, loss is 11.504158586496487\n",
      "Epoch 109 out of 200, loss is 11.400462581135798\n",
      "Epoch 110 out of 200, loss is 11.301858700579032\n",
      "Epoch 111 out of 200, loss is 11.185158031759784\n",
      "Epoch 112 out of 200, loss is 11.06318239402026\n",
      "Epoch 113 out of 200, loss is 10.879562768153846\n",
      "Epoch 114 out of 200, loss is 10.961042448412627\n",
      "Epoch 115 out of 200, loss is 10.681483781663701\n",
      "Epoch 116 out of 200, loss is 10.420977757370565\n",
      "Epoch 117 out of 200, loss is 10.346601986093447\n",
      "Epoch 118 out of 200, loss is 10.198215590673499\n",
      "Epoch 119 out of 200, loss is 10.140787981683388\n",
      "Epoch 120 out of 200, loss is 10.16776460094843\n",
      "Epoch 121 out of 200, loss is 9.987167872022837\n",
      "Epoch 122 out of 200, loss is 9.734550898429006\n",
      "Epoch 123 out of 200, loss is 9.746140789822675\n",
      "Epoch 124 out of 200, loss is 9.522477802122012\n",
      "Epoch 125 out of 200, loss is 9.608278947416693\n",
      "Epoch 126 out of 200, loss is 9.283669993281364\n",
      "Epoch 127 out of 200, loss is 9.28460102842655\n",
      "Epoch 128 out of 200, loss is 9.137801886536181\n",
      "Epoch 129 out of 200, loss is 9.007741455337964\n",
      "Epoch 130 out of 200, loss is 8.910489552421495\n",
      "Epoch 131 out of 200, loss is 8.950565600767732\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m     optimiser.zero_grad()  \u001b[38;5;66;03m# обнулить градиенты\u001b[39;00m\n\u001b[32m     14\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43moptimiser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# провести оптимизацию\u001b[39;00m\n\u001b[32m     17\u001b[39m     running_loss += loss.item()\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, loss is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python_env/local/lib/python3.13/site-packages/torch/optim/optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    512\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    513\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    514\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python_env/local/lib/python3.13/site-packages/torch/optim/optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     84\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python_env/local/lib/python3.13/site-packages/torch/optim/adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python_env/local/lib/python3.13/site-packages/torch/optim/optimizer.py:150\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python_env/local/lib/python3.13/site-packages/torch/optim/adam.py:953\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    951\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python_env/local/lib/python3.13/site-packages/torch/optim/adam.py:777\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    775\u001b[39m     exp_avg_sq_sqrt = torch._foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m777\u001b[39m     exp_avg_sq_sqrt = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m torch._foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[32m    780\u001b[39m torch._foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "total_epochs = 200\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = lenet(images)\n",
    "        loss = cost(outputs, labels)\n",
    "        \n",
    "        optimiser.zero_grad()  # обнулить градиенты\n",
    "        loss.backward()\n",
    "        optimiser.step()  # провести оптимизацию\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} out of {total_epochs}, loss is {running_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397b224-c89d-4ced-b32f-6499c7fe2d4e",
   "metadata": {},
   "source": [
    "### Предсказание LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63a359-1bfd-4738-8cbd-5585110daa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.eval()  # переводим в режим оценки\n",
    "\n",
    "y_net_proba = []\n",
    "y_net =[]\n",
    "\n",
    "with torch.no_grad():  # уменьшить потребление памяти\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = lenet(images)\n",
    "\n",
    "        for proba in outputs.cpu().numpy():  # вероятности\n",
    "            y_net_proba.append(proba)\n",
    "\n",
    "        for label in outputs.argmax(dim=1).cpu().numpy():  # предсказанные классы\n",
    "            y_net.append(label)\n",
    "\n",
    "y_net_proba = np.array(y_net_proba)\n",
    "y_net = np.array(y_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6098b9da-7d4c-48d5-9bae-50ab169e8c09",
   "metadata": {},
   "source": [
    "### Метрики MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8d391-c6f7-4e01-b95c-f0d2b92b2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7198083-9ba6-4761-9779-2aa0f3f9973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_mlp, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e372a12-4736-4908-b93a-71c7454a92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_mlp, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab3e4d-592e-4971-a270-ff7b770ea021",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_mlp, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874b827-bd65-4a16-a863-1dc1533e5802",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_proba, y_mlp_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa4da8a-abbb-435e-bd11-c76e86b84f45",
   "metadata": {},
   "source": [
    "### Метрики LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa088d9d-11b5-4ba8-b199-e09a02e67a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b79be49-c1a1-4add-b20b-0e66920cbc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_net, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d503be54-4124-4946-8e94-69611e94ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_net, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b9dee-810b-4ed7-93f0-6427b1032efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_net, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5bb991-ff0b-4707-96aa-08536f56646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_proba, y_net_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397cb6a-e414-4ff2-9c25-b652b70831c6",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
